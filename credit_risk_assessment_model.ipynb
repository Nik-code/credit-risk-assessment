{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "cba7bcda9de2aceb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Credit Risk Assessment - Model Development\n",
    "This notebook will implement a machine learning pipeline to predict loan status (credit risk). We'll use the insights from the EDA and experiment with various machine learning models."
   ],
   "id": "cfb34d94122fe956"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import required libraries",
   "id": "e13ef7c5b629e8ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T22:43:47.473019Z",
     "start_time": "2024-08-28T22:43:47.468513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "id": "bf90fb4aa8d56feb",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Data Loading and Preprocessing",
   "id": "18dd2f36a8350a0c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-28T22:47:00.449113Z",
     "start_time": "2024-08-28T22:47:00.414724Z"
    }
   },
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('credit_risk_data.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('loan_status', axis=1)\n",
    "y = df['loan_status']"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Feature Engineering",
   "id": "7a8ee27f9ab2025e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We will engineer some new features based on domain knowledge:\n",
    "\n",
    "1. Debt to Income Ratio: Loan amount divided by income.\n",
    "2. Age to Employment Ratio: Person's age divided by employment length plus one."
   ],
   "id": "8131665ef1340884"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T22:47:02.123597Z",
     "start_time": "2024-08-28T22:47:02.119505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "# Custom transformer for feature engineering after preprocessing\n",
    "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_names=None):\n",
    "        self.feature_names = feature_names\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_ = pd.DataFrame(X, columns=self.feature_names)\n",
    "        X_['debt_to_income'] = X_['loan_amnt'] / X_['person_income']\n",
    "        X_['age_to_employment'] = X_['person_age'] / (X_['person_emp_length'] + 1)\n",
    "        return X_.values  # Return as NumPy array for compatibility with the pipeline"
   ],
   "id": "3e8a7d38ed892ecc",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3. Preprocessing: Handling Categorical and Numerical Data\n",
    "We'll create pipelines for preprocessing numerical and categorical data."
   ],
   "id": "fac6dcea913a88e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T22:47:03.236245Z",
     "start_time": "2024-08-28T22:47:03.232007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Identify numeric and categorical columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Define preprocessing steps for numerical and categorical data\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ],
   "id": "b84b1d66aee8cc92",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 4. Model Development and Training\n",
    "We will develop models using Gradient Boosting and XGBoost to predict loan status. We'll also use feature selection and evaluate performance with classification metrics."
   ],
   "id": "dce362ced8bee147"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T22:47:04.409647Z",
     "start_time": "2024-08-28T22:47:04.329913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model 1: Gradient Boosting Classifier\n",
    "gb_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_engineer', FeatureEngineer()),\n",
    "    ('feature_selector', SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42))),\n",
    "    ('model', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "gb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_gb = gb_pipeline.predict(X_test)\n",
    "y_pred_gb_proba = gb_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"Gradient Boosting Classifier Results:\")\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_gb))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred_gb_proba))"
   ],
   "id": "b54966d6f6e12805",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'loan_amnt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 13\u001B[0m\n\u001B[1;32m      5\u001B[0m gb_pipeline \u001B[38;5;241m=\u001B[39m Pipeline([\n\u001B[1;32m      6\u001B[0m     (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpreprocessor\u001B[39m\u001B[38;5;124m'\u001B[39m, preprocessor),\n\u001B[1;32m      7\u001B[0m     (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeature_engineer\u001B[39m\u001B[38;5;124m'\u001B[39m, FeatureEngineer()),\n\u001B[1;32m      8\u001B[0m     (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeature_selector\u001B[39m\u001B[38;5;124m'\u001B[39m, SelectFromModel(RandomForestClassifier(n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m))),\n\u001B[1;32m      9\u001B[0m     (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m'\u001B[39m, GradientBoostingClassifier())\n\u001B[1;32m     10\u001B[0m ])\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[0;32m---> 13\u001B[0m \u001B[43mgb_pipeline\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# Make predictions\u001B[39;00m\n\u001B[1;32m     16\u001B[0m y_pred_gb \u001B[38;5;241m=\u001B[39m gb_pipeline\u001B[38;5;241m.\u001B[39mpredict(X_test)\n",
      "File \u001B[0;32m~/miniconda3/envs/Deep-live/lib/python3.10/site-packages/sklearn/base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1471\u001B[0m     )\n\u001B[1;32m   1472\u001B[0m ):\n\u001B[0;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/Deep-live/lib/python3.10/site-packages/sklearn/pipeline.py:469\u001B[0m, in \u001B[0;36mPipeline.fit\u001B[0;34m(self, X, y, **params)\u001B[0m\n\u001B[1;32m    426\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Fit the model.\u001B[39;00m\n\u001B[1;32m    427\u001B[0m \n\u001B[1;32m    428\u001B[0m \u001B[38;5;124;03mFit all the transformers one after the other and sequentially transform the\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    466\u001B[0m \u001B[38;5;124;03m    Pipeline with fitted steps.\u001B[39;00m\n\u001B[1;32m    467\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    468\u001B[0m routed_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_method_params(method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit\u001B[39m\u001B[38;5;124m\"\u001B[39m, props\u001B[38;5;241m=\u001B[39mparams)\n\u001B[0;32m--> 469\u001B[0m Xt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrouted_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    470\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _print_elapsed_time(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPipeline\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_log_message(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m)):\n\u001B[1;32m    471\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_final_estimator \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpassthrough\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/miniconda3/envs/Deep-live/lib/python3.10/site-packages/sklearn/pipeline.py:406\u001B[0m, in \u001B[0;36mPipeline._fit\u001B[0;34m(self, X, y, routed_params)\u001B[0m\n\u001B[1;32m    404\u001B[0m     cloned_transformer \u001B[38;5;241m=\u001B[39m clone(transformer)\n\u001B[1;32m    405\u001B[0m \u001B[38;5;66;03m# Fit or load from cache the current transformer\u001B[39;00m\n\u001B[0;32m--> 406\u001B[0m X, fitted_transformer \u001B[38;5;241m=\u001B[39m \u001B[43mfit_transform_one_cached\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    407\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcloned_transformer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    408\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    409\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    410\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    411\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmessage_clsname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPipeline\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    412\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmessage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_log_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep_idx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    413\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    414\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    415\u001B[0m \u001B[38;5;66;03m# Replace the transformer of the step with the fitted\u001B[39;00m\n\u001B[1;32m    416\u001B[0m \u001B[38;5;66;03m# transformer. This is necessary when loading the transformer\u001B[39;00m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;66;03m# from the cache.\u001B[39;00m\n\u001B[1;32m    418\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps[step_idx] \u001B[38;5;241m=\u001B[39m (name, fitted_transformer)\n",
      "File \u001B[0;32m~/miniconda3/envs/Deep-live/lib/python3.10/site-packages/joblib/memory.py:312\u001B[0m, in \u001B[0;36mNotMemorizedFunc.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 312\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/Deep-live/lib/python3.10/site-packages/sklearn/pipeline.py:1310\u001B[0m, in \u001B[0;36m_fit_transform_one\u001B[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001B[0m\n\u001B[1;32m   1308\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _print_elapsed_time(message_clsname, message):\n\u001B[1;32m   1309\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(transformer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit_transform\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1310\u001B[0m         res \u001B[38;5;241m=\u001B[39m \u001B[43mtransformer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfit_transform\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1311\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1312\u001B[0m         res \u001B[38;5;241m=\u001B[39m transformer\u001B[38;5;241m.\u001B[39mfit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit\u001B[39m\u001B[38;5;124m\"\u001B[39m, {}))\u001B[38;5;241m.\u001B[39mtransform(\n\u001B[1;32m   1313\u001B[0m             X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtransform\u001B[39m\u001B[38;5;124m\"\u001B[39m, {})\n\u001B[1;32m   1314\u001B[0m         )\n",
      "File \u001B[0;32m~/miniconda3/envs/Deep-live/lib/python3.10/site-packages/sklearn/utils/_set_output.py:313\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[0;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[1;32m    312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 313\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    314\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    315\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[1;32m    316\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    317\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    318\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[1;32m    319\u001B[0m         )\n",
      "File \u001B[0;32m~/miniconda3/envs/Deep-live/lib/python3.10/site-packages/sklearn/base.py:1101\u001B[0m, in \u001B[0;36mTransformerMixin.fit_transform\u001B[0;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[1;32m   1098\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1100\u001B[0m     \u001B[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001B[39;00m\n\u001B[0;32m-> 1101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/Deep-live/lib/python3.10/site-packages/sklearn/utils/_set_output.py:313\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[0;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[1;32m    312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 313\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    314\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    315\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[1;32m    316\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    317\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    318\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[1;32m    319\u001B[0m         )\n",
      "Cell \u001B[0;32mIn[15], line 13\u001B[0m, in \u001B[0;36mFeatureEngineer.transform\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtransform\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[1;32m     12\u001B[0m     X_ \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(X, columns\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_names)\n\u001B[0;32m---> 13\u001B[0m     X_[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdebt_to_income\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mX_\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mloan_amnt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m/\u001B[39m X_[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mperson_income\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     14\u001B[0m     X_[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mage_to_employment\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m X_[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mperson_age\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m/\u001B[39m (X_[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mperson_emp_length\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m X_\u001B[38;5;241m.\u001B[39mvalues\n",
      "File \u001B[0;32m~/miniconda3/envs/Deep-live/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   4100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   4101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 4102\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   4104\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/miniconda3/envs/Deep-live/lib/python3.10/site-packages/pandas/core/indexes/range.py:417\u001B[0m, in \u001B[0;36mRangeIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    415\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m    416\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Hashable):\n\u001B[0;32m--> 417\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n\u001B[1;32m    418\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n\u001B[1;32m    419\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'loan_amnt'"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 5. Model 2: XGBoost\n",
    "We'll use XGBoost and compare it with the Gradient Boosting model."
   ],
   "id": "c5f3698bc578873e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T22:44:39.982095Z",
     "start_time": "2024-08-28T22:44:39.913162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model 2: XGBoost Classifier\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_engineer', FeatureEngineer()),\n",
    "    ('model', XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb_pipeline.predict(X_test)\n",
    "y_pred_xgb_proba = xgb_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nXGBoost Classifier Results:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred_xgb_proba))"
   ],
   "id": "70700f203475cd50",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 9\u001B[0m\n\u001B[1;32m      2\u001B[0m xgb_pipeline \u001B[38;5;241m=\u001B[39m Pipeline([\n\u001B[1;32m      3\u001B[0m     (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpreprocessor\u001B[39m\u001B[38;5;124m'\u001B[39m, preprocessor),\n\u001B[1;32m      4\u001B[0m     (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeature_engineer\u001B[39m\u001B[38;5;124m'\u001B[39m, FeatureEngineer()),\n\u001B[1;32m      5\u001B[0m     (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m'\u001B[39m, XGBClassifier(use_label_encoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, eval_metric\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlogloss\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m      6\u001B[0m ])\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m \u001B[43mxgb_pipeline\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Make predictions\u001B[39;00m\n\u001B[1;32m     12\u001B[0m y_pred_xgb \u001B[38;5;241m=\u001B[39m xgb_pipeline\u001B[38;5;241m.\u001B[39mpredict(X_test)\n",
      "File \u001B[0;32m~/miniconda3/envs/Deep-live/lib/python3.10/site-packages/sklearn/base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1471\u001B[0m     )\n\u001B[1;32m   1472\u001B[0m ):\n\u001B[0;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/Deep-live/lib/python3.10/site-packages/sklearn/pipeline.py:469\u001B[0m, in \u001B[0;36mPipeline.fit\u001B[0;34m(self, X, y, **params)\u001B[0m\n\u001B[1;32m    426\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Fit the model.\u001B[39;00m\n\u001B[1;32m    427\u001B[0m \n\u001B[1;32m    428\u001B[0m \u001B[38;5;124;03mFit all the transformers one after the other and sequentially transform the\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    466\u001B[0m \u001B[38;5;124;03m    Pipeline with fitted steps.\u001B[39;00m\n\u001B[1;32m    467\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    468\u001B[0m routed_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_method_params(method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit\u001B[39m\u001B[38;5;124m\"\u001B[39m, props\u001B[38;5;241m=\u001B[39mparams)\n\u001B[0;32m--> 469\u001B[0m Xt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrouted_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    470\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _print_elapsed_time(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPipeline\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_log_message(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m)):\n\u001B[1;32m    471\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_final_estimator \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpassthrough\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/miniconda3/envs/Deep-live/lib/python3.10/site-packages/sklearn/pipeline.py:406\u001B[0m, in \u001B[0;36mPipeline._fit\u001B[0;34m(self, X, y, routed_params)\u001B[0m\n\u001B[1;32m    404\u001B[0m     cloned_transformer \u001B[38;5;241m=\u001B[39m clone(transformer)\n\u001B[1;32m    405\u001B[0m \u001B[38;5;66;03m# Fit or load from cache the current transformer\u001B[39;00m\n\u001B[0;32m--> 406\u001B[0m X, fitted_transformer \u001B[38;5;241m=\u001B[39m \u001B[43mfit_transform_one_cached\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    407\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcloned_transformer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    408\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    409\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    410\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    411\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmessage_clsname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPipeline\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    412\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmessage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_log_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep_idx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    413\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    414\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    415\u001B[0m \u001B[38;5;66;03m# Replace the transformer of the step with the fitted\u001B[39;00m\n\u001B[1;32m    416\u001B[0m \u001B[38;5;66;03m# transformer. This is necessary when loading the transformer\u001B[39;00m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;66;03m# from the cache.\u001B[39;00m\n\u001B[1;32m    418\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps[step_idx] \u001B[38;5;241m=\u001B[39m (name, fitted_transformer)\n",
      "File \u001B[0;32m~/miniconda3/envs/Deep-live/lib/python3.10/site-packages/joblib/memory.py:312\u001B[0m, in \u001B[0;36mNotMemorizedFunc.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 312\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/Deep-live/lib/python3.10/site-packages/sklearn/pipeline.py:1310\u001B[0m, in \u001B[0;36m_fit_transform_one\u001B[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001B[0m\n\u001B[1;32m   1308\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _print_elapsed_time(message_clsname, message):\n\u001B[1;32m   1309\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(transformer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit_transform\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1310\u001B[0m         res \u001B[38;5;241m=\u001B[39m \u001B[43mtransformer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfit_transform\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1311\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1312\u001B[0m         res \u001B[38;5;241m=\u001B[39m transformer\u001B[38;5;241m.\u001B[39mfit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit\u001B[39m\u001B[38;5;124m\"\u001B[39m, {}))\u001B[38;5;241m.\u001B[39mtransform(\n\u001B[1;32m   1313\u001B[0m             X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtransform\u001B[39m\u001B[38;5;124m\"\u001B[39m, {})\n\u001B[1;32m   1314\u001B[0m         )\n",
      "File \u001B[0;32m~/miniconda3/envs/Deep-live/lib/python3.10/site-packages/sklearn/utils/_set_output.py:313\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[0;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[1;32m    312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 313\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    314\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    315\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[1;32m    316\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    317\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    318\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[1;32m    319\u001B[0m         )\n",
      "File \u001B[0;32m~/miniconda3/envs/Deep-live/lib/python3.10/site-packages/sklearn/base.py:1101\u001B[0m, in \u001B[0;36mTransformerMixin.fit_transform\u001B[0;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[1;32m   1098\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1100\u001B[0m     \u001B[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001B[39;00m\n\u001B[0;32m-> 1101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/Deep-live/lib/python3.10/site-packages/sklearn/utils/_set_output.py:313\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[0;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[1;32m    312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 313\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    314\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    315\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[1;32m    316\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    317\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    318\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[1;32m    319\u001B[0m         )\n",
      "Cell \u001B[0;32mIn[7], line 8\u001B[0m, in \u001B[0;36mFeatureEngineer.transform\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtransform\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[1;32m      7\u001B[0m     X_ \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[0;32m----> 8\u001B[0m     X_[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdebt_to_income\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mX_\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mloan_amnt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m/\u001B[39m X_[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mperson_income\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      9\u001B[0m     X_[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mage_to_employment\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m X_[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mperson_age\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m/\u001B[39m (X_[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mperson_emp_length\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m X_\n",
      "\u001B[0;31mIndexError\u001B[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 6. Model Comparison and Cross-Validation\n",
    "We will compare models using cross-validation."
   ],
   "id": "6e21377ceb43f5b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cross-validation for model comparison\n",
    "models = [\n",
    "    ('Gradient Boosting', gb_pipeline),\n",
    "    ('XGBoost', xgb_pipeline)\n",
    "]\n",
    "\n",
    "for name, model in models:\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='roc_auc')\n",
    "    print(f\"{name} - Mean ROC AUC: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")"
   ],
   "id": "a6b7a263ae082c42"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 7. Feature Importance\n",
    "We'll extract and visualize feature importance from the Gradient Boosting model."
   ],
   "id": "fd6862e47caa7d7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Feature importance for Gradient Boosting Classifier\n",
    "feature_importance = gb_pipeline.named_steps['model'].feature_importances_\n",
    "feature_names = (gb_pipeline.named_steps['preprocessor'].get_feature_names_out().tolist() +\n",
    "                 ['debt_to_income', 'age_to_employment'])\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(feature_importance)[::-1]\n",
    "\n",
    "# Plot top 10 features\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=feature_importance[indices][:10], y=np.array(feature_names)[indices][:10])\n",
    "plt.title('Top 10 Feature Importances - Gradient Boosting Classifier')\n",
    "plt.show()"
   ],
   "id": "30e90759512246fe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
